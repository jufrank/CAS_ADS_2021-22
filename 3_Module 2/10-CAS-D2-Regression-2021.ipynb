{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UnOP-6EzHZ9q"
   },
   "source": [
    "Notebook 3, Module 2, Statistical Inference for Data Science, CAS Applied Data Science, 2021-09-01, A. Mühlemann, University of Bern. \n",
    "\n",
    "*This notebook is based on last year's notebook by S. Haug and G. Conti.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gpx2r-WAHZ9s"
   },
   "source": [
    "# Parameter estimation / regression\n",
    "\n",
    "**Average expected study time :** 3x45 min (depending on your background)\n",
    "\n",
    "**Learning outcomes :**\n",
    "\n",
    "- Know what is meant with parameter estimation and regression\n",
    "- Calculation of a confidence interval via Python\n",
    "- Perform linear regression with Python by example\n",
    "- Perform non-linear regression with Python by example\n",
    "- Know what non-parametric regression is \n",
    "- Perform linear regression with Python scikit-learn by example\n",
    "...\n",
    "\n",
    "**Main python modules used**\n",
    "- the Scipy.stat module https://docs.scipy.org/doc/scipy/reference/stats.html\n",
    "- the Scikit-learn module\n",
    "\n",
    "If you run this notebook on google colab, you will (probably) have no problems with importing the modules."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bprX1FRLHZ9t"
   },
   "source": [
    "## What you should do for your uncertainties"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s0V7y6PiHZ9u"
   },
   "source": [
    "When you have a data analysis project, you need to define the final numbers and plots you want to produce. In order to control your uncertaines, you should maintain a list/table with the largest uncertainties and their effect on the final number(s) as percentages.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrHViWYQHZ9x"
   },
   "source": [
    "# 3. Inferential Statistics I\n",
    "\n",
    "In this notebook we apply the methods presented in the course on the iris data set. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3rFRb9rhHZ90"
   },
   "source": [
    "Import the Python libraries we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "St85roiBHZ91"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y-6YDunfZZpk"
   },
   "source": [
    "Import the iris data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "YSg-y1hgHZ99"
   },
   "outputs": [],
   "source": [
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data\"\n",
    "df = pd.read_csv(url,names=['slength','swidth','plength','pwidth','species'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cWPbHuDbVzVG"
   },
   "source": [
    "## 3.1 Model parameter estimation\n",
    "Let us start with model parameter estimation. To this end, we go back to the outlook from the first notebook. There, we calculated the kurtosis and skewness for the different characteristics and species. We observed that the characteristic *slength* from of the species *iris virginica* has a kurtosis and skewness close to zero. We therefore concluded that a Gaussian model would probably be suitable. (We will see how to further justify that tomorrow) \n",
    "Let us  estimate the mean and standard deviation of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 574,
     "status": "ok",
     "timestamp": 1629967934685,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "EHC4Q_mOVspZ",
    "outputId": "ffcfee5f-ce35-4fd0-f4b7-72fd6a6b4e44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.587999999999998 0.635879593274432\n"
     ]
    }
   ],
   "source": [
    "# Estimation of mean and standard deviation\n",
    "df_virginica=df[df['species']=='Iris-virginica']\n",
    "from scipy.stats import norm\n",
    "mean  = df_virginica['slength'].mean()\n",
    "sd = df_virginica['slength'].std()\n",
    "print(mean,sd)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jT_04i14cuDM"
   },
   "source": [
    "So we get a mean of about 6.59 and a standard deviation of 0.64. Now let us see how the histogram of *slength* of *iris virginica* looks compared to our estimated model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1629967937746,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "2cM7b2eiYwbK",
    "outputId": "7208215b-b47d-417c-e0df-92bef703a85a"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Create figure and axis\n",
    "fig, ax = plt.subplots(1,1)\n",
    "# Create 100 x values and plot the normal pdf for these values\n",
    "#x = np.linspace(norm.ppf(0.01),norm.ppf(0.99), 100)\n",
    "x = np.linspace(4,10,80)\n",
    "ax.plot(x, norm.pdf(x,mean,sd),'b-', lw=2, label='Normed pdf')\n",
    "df_virginica['slength'].plot(kind=\"hist\",fill=False,histtype='step',title='Iris Virginica Setal', label=\"length\", density=\"True\")\n",
    "ax.legend(loc='best', frameon=False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qlcjT_YeYr7T"
   },
   "source": [
    "Looks ot bad, the right tail of the histogramm is a bit heavier than we would expect from a normal distribution. Let check tomorrow whether a normal model is indeed justified - especially since the sample size is rather small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hOVBrT0WdjrZ"
   },
   "source": [
    "## 3.2 Confidence intervall\n",
    "At the moment we have no clue on how certain we are about point estimates for the mean and standard deviation we calculated above. Hence, it makes sense to additionally look at the confidence intervals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 336,
     "status": "ok",
     "timestamp": 1629966225387,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "MqZxZqfjhOs5",
    "outputId": "62fe563d-632b-4e79-eea3-911f9059750d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.4072850193549105, 6.768714980645086)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#95%-confidence interval for the mean\n",
    "stats.t.interval(alpha=0.95, df=len(df_virginica['slength'])-1, loc=np.mean(df_virginica['slength']), scale=stats.sem(df_virginica['slength'])) \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFGWWHEgi5Vu"
   },
   "source": [
    "If we already know that our data is normally distributed, we could also use the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 328,
     "status": "ok",
     "timestamp": 1629966420274,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "-o8ihs5Zj5IZ",
    "outputId": "131afe1f-f739-4d14-e50f-24eb9282690a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6.411746407971008, 6.764253592028989)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#95%-confidence interval for the when data is normally distirbuted\n",
    "stats.norm.interval(alpha=0.95, loc=np.mean(df_virginica['slength']), scale=stats.sem(df_virginica['slength']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOczDpjAj4m1"
   },
   "source": [
    "We can see that the confidence interval based on the t-distribution is a bit more conservative. But for this example the difference between the two is really small.\n",
    "\n",
    "Unfortunately, there is no Python library that computes the confidence interval of standard deviation, so we have to do it \"by hand\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1629967162822,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "X6E1O5idl5Cu",
    "outputId": "b96b66fd-7621-4f3a-97b0-74d84d2b68b2"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.5311718507243312, 0.7923907741872332)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# confidence intervall for the standard deviation of normally distributed data\n",
    "alpha = 0.05  # significance level = 5%\n",
    "n = len(df_virginica['slength'])  # sample sizes\n",
    "s2 = np.var(df_virginica['slength'], ddof=1)   # sample variance\n",
    "df = n - 1                 # degrees of freedom\n",
    "\n",
    "upper = np.sqrt((n - 1) * s2 / stats.chi2.ppf(alpha / 2, df))\n",
    "lower = np.sqrt((n - 1) * s2 / stats.chi2.ppf(1 - alpha / 2, df))\n",
    "(lower, upper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFHy-HgEnVTI"
   },
   "source": [
    "Try to calculate the confidence intervals for the other 2 species.\n",
    "\n",
    "You can find more on confidence intervals under https://aegis4048.github.io/comprehensive_confidence_intervals_for_python_developers#chi_square\n",
    "I found this Link quite helpful :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ldd4t9BUHZ9y"
   },
   "source": [
    "## 3.1 About linear Regression\n",
    "\n",
    "(Simple) linear regression means fitting a straight line to data a set of points (x,y). You may consider this as the simplest case of Machine Learning (see Module 3). A line is described as\n",
    "\n",
    "$$y = ax + b$$\n",
    "\n",
    "Thus two parameters a (slope) and b (intersection with y axis) are fitted.\n",
    "\n",
    "There are different fitting methods, mostly least squares or maximum likelihood are used. See the lecture for some introduction to these two methods. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tCRukbUyHZ9z"
   },
   "source": [
    "## Linear regression in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vVN3HiA_HZ98"
   },
   "source": [
    "In notebook 1 we observed that there seems to be a rather strong correlation between slength-swidth in the setosa species. Let us further investigate this observation via linear regression. We use https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.linregress.html, using least squares. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 335,
     "status": "ok",
     "timestamp": 1629968424018,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "37bwidp9ZR9Y",
    "outputId": "eb51616e-089e-47e2-ed51-ea91748466f3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8072336651226962 -0.6230117276042177\n",
      "                                 OLS Regression Results                                \n",
      "=======================================================================================\n",
      "Dep. Variable:                slength   R-squared (uncentered):                   0.995\n",
      "Model:                            OLS   Adj. R-squared (uncentered):              0.994\n",
      "Method:                 Least Squares   F-statistic:                              8892.\n",
      "Date:                Wed, 01 Sep 2021   Prob (F-statistic):                    4.54e-57\n",
      "Time:                        12:25:56   Log-Likelihood:                         -21.436\n",
      "No. Observations:                  50   AIC:                                      44.87\n",
      "Df Residuals:                      49   BIC:                                      46.79\n",
      "Df Model:                           1                                                  \n",
      "Covariance Type:            nonrobust                                                  \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "swidth         1.4553      0.015     94.295      0.000       1.424       1.486\n",
      "==============================================================================\n",
      "Omnibus:                        1.351   Durbin-Watson:                   2.096\n",
      "Prob(Omnibus):                  0.509   Jarque-Bera (JB):                0.599\n",
      "Skew:                           0.131   Prob(JB):                        0.741\n",
      "Kurtosis:                       3.468   Cond. No.                         1.00\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] R² is computed without centering (uncentered) since the model does not contain a constant.\n",
      "[2] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n"
     ]
    }
   ],
   "source": [
    "df_setosa = df[df['species']=='Iris-setosa']\n",
    "slengths = df_setosa['slength']\n",
    "swidths  = df_setosa['swidth']\n",
    "slope, intercept, r_value, p_value, std_err = stats.linregress(slengths,swidths)\n",
    "print (slope, intercept)\n",
    "stats.linregress(slengths,swidths)\n",
    "\n",
    "from pandas import DataFrame\n",
    "import statsmodels.api as sm\n",
    "model = sm.OLS(slengths, swidths).fit()\n",
    "predictions = model.predict(swidths) \n",
    "\n",
    "print_model = model.summary()\n",
    "print(print_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "j-8oRlJ5yjs2"
   },
   "source": [
    "Slope estimate +/- standard error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 352,
     "status": "ok",
     "timestamp": 1629970246007,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "0VPP4xJhyh3K",
    "outputId": "7b9e9ccf-e3fc-4b7d-b676-61b81ce05856"
   },
   "outputs": [],
   "source": [
    "print ('%1.2f +- %1.2f' % (slope,std_err))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KWnUMLNuHZ-C"
   },
   "source": [
    " To get the coefficient of determination $R^2$, i.e. the proportion of the variation in the $y$ that is predictable from the $x$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 470,
     "status": "ok",
     "timestamp": 1629968807111,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "6bCN6tOXHZ-D",
    "outputId": "a9114941-d97c-4135-875f-abfbf7f20a2e"
   },
   "outputs": [],
   "source": [
    "(\"r-squared:\", r_value**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V3BFeEvyHZ-J"
   },
   "source": [
    "Let's look at the scatter plot to see if this makes sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 397,
     "status": "ok",
     "timestamp": 1629968428049,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "b4ZfkosnHZ-J",
    "outputId": "ccaee60b-77b8-4129-adb9-fa22654f72a8"
   },
   "outputs": [],
   "source": [
    "ax = df_setosa.plot(x='slength',y='swidth',kind=\"scatter\",c='c')\n",
    "plt.plot(slengths, intercept + slope*slengths, 'b', label='Fitted treated line')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4h0bIb7lHZ-h"
   },
   "source": [
    "The fit looks okay but there is some variation in the sample. How about the other species? \n",
    "\n",
    "We now have a model, a straight line, whose shape we have chosen, but whose parameters (slope and intersection) have been estimated/fitted from data with the least squares method. It tells us that $swidth$ of a leaf is $slength \\times slope$ $(f(slength) = a \\times slope)$. So we can do interpolation and extrapolation, i.e. get the swidth at any slength.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EW2fVflHZ-i"
   },
   "source": [
    "### Example Exponential p.d.f.\n",
    "\n",
    "With scale $\\beta$ and location $\\mu$\n",
    "\n",
    "$$f(x)=\\frac{1}{\\beta} e^{-(x-\\mu)/\\beta}     ,  x \\ge \\mu;\\beta>0$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 357,
     "status": "ok",
     "timestamp": 1629969003115,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "6eu7CsUFHZ-j",
    "outputId": "78b3bbfa-1110-4c76-fcd5-252c0b1743a4"
   },
   "outputs": [],
   "source": [
    "# Let us fit data to an exponential distribution\n",
    "fig, ax = plt.subplots(1, 1)\n",
    "# First generate a data set from a exponential distribution\n",
    "x = stats.expon.rvs(0.0,0.5,size=100) #  scale = 0.5, location = 0.00, 100 variates\n",
    "ax.hist(x, density=True, histtype='stepfilled', alpha=0.2)\n",
    "# Fit scale and location to the histogram/data\n",
    "loc, scale = stats.expon.fit(x) # ML estimator scale, lambda * exp(-lambda * x), scale =1/lambda\n",
    "print(' Location = %1.2f , Scale = %1.2f' % (loc,scale)) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OGXrcmQnHZ-o"
   },
   "source": [
    "If you run this code serval times, you'll observe that sometimes th fit is rather poor. Here, we know the true underlying distribution but in general we don't. Thus, it would be helpful to know the uncertainties on the fitted values. The curve_fit method below also returns the uncertainties."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rzjGIJouHZ-p"
   },
   "source": [
    "## 3.2 Non-linear regression\n",
    "\n",
    "If a line is not straight it is curved. There are many mathematical functions whose parameters we can try to fit to experimental data points. Some examples: Polynominals (first order is linear regression, second order is a parabola etc), exponential functions, normal function, sindoial wave function etc. You need to choose an approriate shape/function to obtain a good result. \n",
    "\n",
    "With the Scipy.stat module we can look for preprogrammed functions (in principle you can program your own function whose parameters you want to fit too): https://docs.scipy.org/doc/scipy/reference/stats.html. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "831QxcoRHZ-p"
   },
   "source": [
    "The scipy.optimize module provides a more general non-linear least squares fit. Look at and play with this example. It is complex and you will probably use some time to fully understand every step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 410,
     "status": "ok",
     "timestamp": 1629970086465,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "1wsB4y-wHZ-q",
    "outputId": "5dff26cc-78cb-4d44-de7b-350dd428551b"
   },
   "outputs": [],
   "source": [
    "from scipy.optimize import curve_fit\n",
    "\n",
    "def func(x, a, b, c):\n",
    "     return a * np.exp(-b * x) + c\n",
    "\n",
    "xdata = np.linspace(0, 4, 50) # \n",
    "y = func(xdata, 2.5, 1.3, 0.5)\n",
    "plt.plot(xdata, y, 'g-', label='Generated data')\n",
    "np.random.seed(1729)\n",
    "y_noise = 0.2 * np.random.normal(size=xdata.size)\n",
    "ydata = y + y_noise\n",
    "plt.plot(xdata, ydata, 'bo', label='Generated data with noise')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EssTbnMBvvI7"
   },
   "source": [
    "Let's fit the curve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 315
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1629970070122,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "FizQcBT1HZ-v",
    "outputId": "e9df91ba-642e-443d-a1d4-93315a774fdc"
   },
   "outputs": [],
   "source": [
    "popt, pcov = curve_fit(func, xdata, ydata)\n",
    "print(popt)\n",
    "plt.plot(xdata, func(xdata, *popt), 'r-',label= \\\n",
    "         'fit: a=%5.3f +- %5.3f, \\n b=%5.3f +- %5.3f, \\n c=%5.3f +-%5.3f' % \\\n",
    "         (popt[0],perr[0],popt[1],perr[1],popt[2],perr[2]))\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "# pcov is the covariance matrix. The errors**2 of each parameter are the values on the diagonal.\n",
    "perr = np.sqrt(np.diag(pcov)) # Standard deviation = square root of the variance being on the diagonal of the covariance matrix\n",
    "perr\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9e_ZppEZvzi0"
   },
   "source": [
    "Compare it to the data and the true function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "executionInfo": {
     "elapsed": 881,
     "status": "ok",
     "timestamp": 1629970074484,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "aOuM_jywv6Vu",
    "outputId": "5b4d0b16-7129-437d-e375-5a3720cd0efa"
   },
   "outputs": [],
   "source": [
    "plt.plot(xdata, y, 'g-', label='true')\n",
    "plt.plot(xdata, func(xdata, *popt), 'r-',label= 'fit')\n",
    "plt.plot(xdata, ydata, 'bo', label='Generated data with noise')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sfYUc2gayS7n"
   },
   "source": [
    "Try to add a bit more noise and rerun the code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "N399vCV4HZ-z"
   },
   "source": [
    "# 3.3 Non-parametric regression\n",
    "\n",
    "So far we have used functions (models) with some predefined model. The parameters we fitted to data. If we have no clue about the model, but a rought idea on the shape non-parametric methods like isotonic regression. However, these require more data as also the exact shape needs to guessed or fitted from the data. So normally a non-parametric method gives poorer results. \n",
    "\n",
    "There are several ways to do this in Python. You make look at this if you are interested:\n",
    "\n",
    "https://pythonhosted.org/PyQt-Fit/NonParam_tut.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uxKmRNrRHZ-0"
   },
   "source": [
    "# 3.4 Fitting with scikit-learn\n",
    "\n",
    "When it comes to machine learning, the `scikit-learn` module is much richer than the stats module. You can find extensive documentation with examples in the [user guide](https://scikit-learn.org/stable/user_guide.html)\n",
    "\n",
    "The module contains A LOT of different machine learning methods, and here we will cover only few of them. What is great about `scikit-learn` is that it has a uniform and consistent interface. \n",
    "\n",
    "All the different ML approaches are implemented as classes with a set of same main methods:\n",
    "\n",
    "1. `fitter = ...`: Create object.\n",
    "2. `fitter.fit(x, y[, sample_weight])`: Fit model.\n",
    "3. `y_pred = fitter.predict(X)`: Predict using the model.\n",
    "4. `s = fitter.score(x, y[, sample_weight])`: Return an appropriate measure of model performance.\n",
    "\n",
    "This allows us to easily replace one approach with another and find the best one for the problem at hand, by simply using another regression/classification object, while the rest of the code can remain the same.\n",
    "\n",
    "But you should be careful that there remains some justification! Otherwise you'll overfit. To be sure, you should use an approach like cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 446,
     "status": "ok",
     "timestamp": 1629970756668,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "ezmW4pb2HZ-1"
   },
   "outputs": [],
   "source": [
    "# Let's write a method which can generate a linear dataset\n",
    "# with n_d dimensions and some gaussian noise to it\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def get_linear(n_d=1, n_points=10, w=None, b=None, sigma=5):\n",
    "  x = np.random.uniform(0, 10, size=(n_points, n_d))\n",
    "  \n",
    "  w = w or np.random.uniform(0.1, 10, n_d)\n",
    "  b = b or np.random.uniform(-10, 10)\n",
    "  y = np.dot(x, w) + b + np.random.normal(0, sigma, size=n_points)\n",
    "\n",
    "  print('true w =', w, ';  b =', b)\n",
    "\n",
    "  return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 301
    },
    "executionInfo": {
     "elapsed": 389,
     "status": "ok",
     "timestamp": 1629970935497,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "GlsmKqA_HZ-7",
    "outputId": "6decfe70-7047-424c-d858-851aa5c3c7a7"
   },
   "outputs": [],
   "source": [
    "# Sample data from a straight line with noise to it \n",
    "x, y = get_linear(n_d=1, n_points=10)\n",
    "plt.plot(x[:, 0], y, '*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 333,
     "status": "ok",
     "timestamp": 1629970937888,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "NbGHUG25Jr_n",
    "outputId": "17519957-eb3c-4ab0-ca65-cc14c3be5712"
   },
   "outputs": [],
   "source": [
    "from sklearn import linear_model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 348,
     "status": "ok",
     "timestamp": 1629970940194,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "94oQqhyTKHlX",
    "outputId": "f8e4cc06-4317-45bf-8e94-e77f0f77eacf"
   },
   "outputs": [],
   "source": [
    "w, w0 = reg.coef_, reg.intercept_\n",
    "print(w, w0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QSNozJUJTSFa"
   },
   "source": [
    "scikit-learn does not support calculation of covariance on fitted parameters. That is a pity maybe. However, we can use numpy vectorized methods.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 342,
     "status": "ok",
     "timestamp": 1629970946137,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "rJIV5pKmUPSz",
    "outputId": "ed8c9b98-e670-4eae-baec-34352919dbd4"
   },
   "outputs": [],
   "source": [
    "np.std(y - reg.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1629970949415,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "RF6OAUOkUQ9b",
    "outputId": "be93a84b-413d-4f5e-caa1-3a5864bc3ecf"
   },
   "outputs": [],
   "source": [
    "(np.cov(y - reg.predict(x)))**0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "executionInfo": {
     "elapsed": 428,
     "status": "ok",
     "timestamp": 1629970987766,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "tzWRQdCATrl9",
    "outputId": "33a85bf2-b95b-4b86-eb07-9df2fee9abc6"
   },
   "outputs": [],
   "source": [
    "# Plot the fitted model with plus minus one standard deviation.\n",
    "# Are the data points distributed as expected?\n",
    "plt.scatter(x, y, marker='*')\n",
    "x_f = np.linspace(x.min(), x.max(), 10)\n",
    "y_f = w0 + w[0] * x_f\n",
    "plt.plot(x_f, y_f)\n",
    "plt.plot(x_f, y_f+5.5)\n",
    "plt.plot(x_f, y_f-5.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 502
    },
    "executionInfo": {
     "elapsed": 705,
     "status": "ok",
     "timestamp": 1629970997200,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "JddYy37lHZ-_",
    "outputId": "b34555a6-147a-42fc-9a72-996ce24cc9b6"
   },
   "outputs": [],
   "source": [
    "# Generate data points from a plane with some noise to it (default) \n",
    "n_d = 2\n",
    "x, y = get_linear(n_d=n_d, n_points=100)\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x[:,0], x[:,1], y, marker='x', color='b',s=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 339,
     "status": "ok",
     "timestamp": 1629971004160,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "VinHbzEjIBFm",
    "outputId": "1dcf35bf-d585-47da-987a-af9491aae6dc"
   },
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 484
    },
    "executionInfo": {
     "elapsed": 797,
     "status": "ok",
     "timestamp": 1629971027153,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "pdeRD7-ZTf0A",
    "outputId": "cbce5745-d7f5-41db-cb2f-7054ebd93a55"
   },
   "outputs": [],
   "source": [
    "# When doing ML, it is recommended to split the dataset into a training\n",
    "# and a test set. The training set is used to learn the parameters. The \n",
    "# test set can be used to assess the performance of the trained model \n",
    "# (overfitting and underfitting). sklearn provides a helpful method doing that. \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "n_d = 2\n",
    "x, y = get_linear(n_d=n_d, n_points=100, sigma=5)\n",
    "\n",
    "# train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(8,8))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x_train[:,0], x_train[:,1], y_train, marker='x', color='b',s=40)\n",
    "ax.scatter(x_test[:,0], x_test[:,1], y_test, marker='+', color='r',s=80)\n",
    "\n",
    "xx0 = np.linspace(x[:,0].min(), x[:,0].max(), 10)\n",
    "xx1 = np.linspace(x[:,1].min(), x[:,1].max(), 10)\n",
    "xx0, xx1 = [a.flatten() for a in np.meshgrid(xx0, xx1)]\n",
    "xx = np.stack((xx0, xx1), axis=-1)\n",
    "yy = reg.predict(xx)\n",
    "ax.plot_trisurf(xx0, xx1, yy, alpha=0.5, color='g');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 416,
     "status": "ok",
     "timestamp": 1629971033347,
     "user": {
      "displayName": "Anja Mühlemann",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhwhHexcG2jbw7iRoG_jTJDhebm4W6zC_tS4dTcqQ=s64",
      "userId": "13180139022750424409"
     },
     "user_tz": -120
    },
    "id": "3xw69ZnYY7R2",
    "outputId": "4a1be5c3-f340-4ed7-f120-abbdd5e3f2db"
   },
   "outputs": [],
   "source": [
    "np.std(y-reg.predict(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UAFWFkR4gaAf"
   },
   "source": [
    "## End of notebook\n",
    "\n",
    "We have now seen how to calculate confidence intervals and do linear regression with several python modules. The most popular ML models are implemented in sklearn. We don't have time practicing them in this Module. In Module 3 we will learn and practice deep neural networks.\n",
    "\n",
    "Please post a question about today's content here:\n",
    "\n",
    "https://forms.gle/kUjTJVy2AkqZuFcXA\n",
    "\n",
    "Many thanks and see you tomorrow !\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f2sQVIJP0r9B"
   },
   "source": [
    "## Extra - Much used ML performance measures\n",
    "\n",
    "1. Regression:\n",
    "* Mean Square Error (MSE): $mse=\\frac{1}{n}\\sum_i(y_i - \\hat y(\\bar x_i))^2$\n",
    "* Mean Absolute Error (MAE): $mae=\\frac{1}{n}\\sum_i|y_i - \\hat y(\\bar x_i)|$\n",
    "* Median Absolute Deviation (MAD): $mad=median(|y_i - \\hat y(\\bar x_i)|)$\n",
    "* Fraction of the explained variance: $R^2=1-\\frac{\\sum_i(y_i - \\hat y(\\bar x_i))^2}{\\sum_i(y_i - \\bar y_i)^2}$, where $\\bar y=\\frac{1}{n}\\sum_i y_i$\n",
    "\n",
    "2. Classification:\n",
    "* Confusion matrix \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QzuLxxBD1kdR"
   },
   "source": [
    "<img src=\"https://github.com/neworldemancer/DSF5/raw/master/figures/confusion_mtr.png\" width=\"60%\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7E9smfEP1ork"
   },
   "source": [
    "* Accuracy $=\\frac{TP+TN}{TP+FP+FN+TN}$\n",
    "* Precision $=\\frac{TP}{TP+FP}$\n",
    "* Recall $=\\frac{TP}{TP+FN}$\n",
    "* F1 $=2\\frac{Precision \\cdot Recall}{Precision+Recall} = \\frac{2 TP}{2 TP + FP+FN}$\n",
    "* Threat score (TS), or Intersection over Union (IoU): IoU=$\\frac{TP}{TP+FN+FP}$\n",
    "\n",
    "During model optimization the used measure in most cases must be differentiable. To this end usually some measure of similarities of distributions are employed (e.g. cross-entropy)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "U1J7txZf1vCg"
   },
   "source": [
    "## Extra - Predicting House Prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "b7TxGOtf2ZMY"
   },
   "outputs": [],
   "source": [
    "# First write a method loading and cleaning the data\n",
    "def house_prices_dataset(return_df=False, price_max=400000, area_max=40000):     \n",
    "  path = 'https://raw.githubusercontent.com/neworldemancer/DSF5/master/data/AmesHousing.csv'\n",
    "  df = pd.read_csv(path, na_values=('NaN', ''), keep_default_na=False)\n",
    "  df.head()\n",
    "  rename_dict = {k:k.replace(' ', '').replace('/', '') for k in df.keys()}\n",
    "  df.rename(columns=rename_dict, inplace=True)\n",
    "  \n",
    "  useful_fields = ['LotArea',\n",
    "                  'Utilities', 'OverallQual', 'OverallCond',\n",
    "                  'YearBuilt', 'YearRemodAdd', 'ExterQual', 'ExterCond',\n",
    "                  'HeatingQC', 'CentralAir', 'Electrical',\n",
    "                  '1stFlrSF', '2ndFlrSF','GrLivArea',\n",
    "                  'FullBath', 'HalfBath',\n",
    "                  'BedroomAbvGr', 'KitchenAbvGr', 'KitchenQual', 'TotRmsAbvGrd',\n",
    "                  'Functional','PoolArea',\n",
    "                  'YrSold', 'MoSold'\n",
    "                  ]\n",
    "  target_field = 'SalePrice'\n",
    "\n",
    "  df.dropna(axis=0, subset=useful_fields+[target_field], inplace=True)\n",
    "\n",
    "  cleanup_nums = {'Street':      {'Grvl': 0, 'Pave': 1},\n",
    "                  'LotFrontage': {'NA':0},\n",
    "                  'Alley':       {'NA':0, 'Grvl': 1, 'Pave': 2},\n",
    "                  'LotShape':    {'IR3':0, 'IR2': 1, 'IR1': 2, 'Reg':3},\n",
    "                  'Utilities':   {'ELO':0, 'NoSeWa': 1, 'NoSewr': 2, 'AllPub': 3},\n",
    "                  'LandSlope':   {'Sev':0, 'Mod': 1, 'Gtl': 3},\n",
    "                  'ExterQual':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'ExterCond':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'BsmtQual':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'BsmtCond':    {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'BsmtExposure':{'NA':0, 'No':1, 'Mn': 2, 'Av': 3, 'Gd': 4},\n",
    "                  'BsmtFinType1':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
    "                  'BsmtFinType2':{'NA':0, 'Unf':1, 'LwQ': 2, 'Rec': 3, 'BLQ': 4, 'ALQ':5, 'GLQ':6},\n",
    "                  'HeatingQC':   {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'CentralAir':  {'N':0, 'Y': 1},\n",
    "                  'Electrical':  {'':0, 'NA':0, 'Mix':1, 'FuseP':2, 'FuseF': 3, 'FuseA': 4, 'SBrkr': 5},\n",
    "                  'KitchenQual': {'Po':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'Functional':  {'Sal':0, 'Sev':1, 'Maj2': 2, 'Maj1': 3, 'Mod': 4, 'Min2':5, 'Min1':6, 'Typ':7},\n",
    "                  'FireplaceQu': {'NA':0, 'Po':1, 'Fa': 2, 'TA': 3, 'Gd': 4, 'Ex':5},\n",
    "                  'PoolQC':      {'NA':0, 'Fa': 1, 'TA': 2, 'Gd': 3, 'Ex':4},\n",
    "                  'Fence':       {'NA':0, 'MnWw': 1, 'GdWo': 2, 'MnPrv': 3, 'GdPrv':4},\n",
    "                  }\n",
    "\n",
    "  df_X = df[useful_fields].copy()                              \n",
    "  df_X.replace(cleanup_nums, inplace=True)  # convert continous categorial variables to numerical\n",
    "  df_Y = df[target_field].copy()\n",
    "\n",
    "  x = df_X.to_numpy().astype(np.float32)\n",
    "  y = df_Y.to_numpy().astype(np.float32)\n",
    "\n",
    "  if price_max>0:\n",
    "    idxs = y<price_max\n",
    "    x = x[idxs]\n",
    "    y = y[idxs]\n",
    "\n",
    "  if area_max>0:\n",
    "    idxs = x[:,0]<area_max\n",
    "    x = x[idxs]\n",
    "    y = y[idxs]\n",
    "\n",
    "  return (x, y, df) if return_df else (x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 398
    },
    "id": "8gzDWJDd11XC",
    "outputId": "309bdc1a-14a4-4ea0-abf1-f252e58f994d"
   },
   "outputs": [],
   "source": [
    "# Solution:\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x, y = house_prices_dataset()\n",
    "\n",
    "# 1. make train/test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)\n",
    "\n",
    "# 2. fit the model\n",
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(x_train, y_train)\n",
    "\n",
    "# 3. evaluate MSE, MAD, and R2 on train and test datasets\n",
    "#prediction:\n",
    "y_p_train = reg.predict(x_train)\n",
    "y_p_test = reg.predict(x_test)\n",
    "\n",
    "# mse\n",
    "print('train mse =', np.std(y_train - y_p_train))\n",
    "print('test mse =', np.std(y_test - y_p_test))\n",
    "# mse\n",
    "print('train mae =', np.mean(np.abs(y_train - y_p_train)))\n",
    "print('test mae =', np.mean(np.abs(y_test - y_p_test)))\n",
    "# R2\n",
    "print('train R2 =', reg.score(x_train, y_train))\n",
    "print('test R2 =', reg.score(x_test, y_test))\n",
    "\n",
    "# 4. plot y vs predicted y for test and train parts\n",
    "plt.plot(y_train, y_p_train, 'b.', label='train')\n",
    "plt.plot(y_test, y_p_test, 'r.', label='test')\n",
    "\n",
    "plt.plot([0], [0], 'w.')  # dummy to have origin\n",
    "plt.xlabel('true')\n",
    "plt.ylabel('predicted')\n",
    "plt.gca().set_aspect('equal')\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "06-CAS-D2-Regression-2021.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
